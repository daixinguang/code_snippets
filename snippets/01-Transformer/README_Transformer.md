# Transformer模型结构

Transformer模型中面试常问的知识点和代码实现。

尽可能使用ipynb文件来文字代码结合记录。

## 路径

| PATH | NOTEs |
| :-- | :-- |
| [self_attention.ipynb](./self_attention.ipynb) | Transformer自注意力机制 |
| [multi_head_self_attention.ipynb](./multi_head_self_attention.ipynb) | Transformer多头注意力 |
